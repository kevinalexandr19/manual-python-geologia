{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da57f3cb-5a2b-4b2e-ba12-d31fbf53424a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div align=\"center\">\n",
    "    <span style=\"font-size:30px\">\n",
    "        <strong>\n",
    "            <!-- Símbolo de Python -->\n",
    "            <img\n",
    "                src=\"https://cdn3.emoji.gg/emojis/1887_python.png\"\n",
    "                style=\"margin-bottom:-5px\"\n",
    "                width=\"30px\" \n",
    "                height=\"30px\"\n",
    "            >\n",
    "            <!-- Título -->\n",
    "            Python para Geólogos\n",
    "            <!-- Versión -->\n",
    "            <img \n",
    "                src=\"https://img.shields.io/github/release/kevinalexandr19/manual-python-geologia.svg?style=flat&label=&color=blue\"\n",
    "                style=\"margin-bottom:-2px\" \n",
    "                width=\"40px\"\n",
    "            >\n",
    "        </strong>\n",
    "    </span>\n",
    "    <br>\n",
    "    <span>\n",
    "        <!-- Github del proyecto -->\n",
    "        <a href=\"https://github.com/kevinalexandr19/manual-python-geologia\" target=\"_blank\">\n",
    "            <img src=\"https://img.shields.io/github/stars/kevinalexandr19/manual-python-geologia.svg?style=social&label=Github Repo\">\n",
    "        </a>\n",
    "        &nbsp;&nbsp;\n",
    "        <!-- Licencia -->\n",
    "        <img src=\"https://img.shields.io/github/license/kevinalexandr19/manual-python-geologia.svg?color=forestgreen\">\n",
    "        &nbsp;&nbsp;\n",
    "        <!-- Release date -->\n",
    "        <img src=\"https://img.shields.io/github/release-date/kevinalexandr19/manual-python-geologia?color=gold\">\n",
    "    </span>\n",
    "    <br>\n",
    "    <span>\n",
    "        <!-- Perfil de LinkedIn -->\n",
    "        <a target=\"_blank\" href=\"https://www.linkedin.com/in/kevin-alexander-gomez/\">\n",
    "            <img src=\"https://img.shields.io/badge/-Kevin Alexander Gomez-5eba00?style=social&logo=linkedin\">\n",
    "        </a>\n",
    "        &nbsp;&nbsp;\n",
    "        <!-- Perfil de Github -->\n",
    "        <a target=\"_blank\" href=\"https://github.com/kevinalexandr19\">\n",
    "            <img src=\"https://img.shields.io/github/followers/kevinalexandr19.svg?style=social&label=kevinalexandr19&maxAge=2592000\">\n",
    "        </a>\n",
    "    </span>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5d6ea-8130-4aa8-a9d1-e1c96c5b8273",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:lightgreen; font-size:25px\">**PG201 - Aprendizaje supervisado**</span>\n",
    "\n",
    "Bienvenido al curso!!!\n",
    "\n",
    "Vamos a revisar diferentes algoritmos de <span style=\"color:gold\">aprendizaje supervisado</span> y su aplicación en Geología. <br>\n",
    "Es necesario que tengas un conocimiento previo en programación con Python, álgebra lineal, estadística y geología.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ac84a-92a9-47c7-99d1-5ae5c0209381",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:gold; font-size:20px\">**Random Forest (RF)**</span>\n",
    "\n",
    "***\n",
    "- [¿En qué consiste Random Forest?](#parte-1)\n",
    "- [Random Forest en Python](#parte-2)\n",
    "- [Evaluación del modelo](#parte-3)\n",
    "- [Importancia de las características](#parte-4)\n",
    "- [En conclusión...](#parte-5)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6307722-0810-4e35-9b12-21d4d3c1513f",
   "metadata": {},
   "source": [
    "<a id=\"parte-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799c802-d0b2-49bc-a897-e26bc2d5f224",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightgreen\">**¿En qué consiste el algoritmo de Random Forest?**</span>\n",
    "***\n",
    "\n",
    "Random Forest es un <span style=\"color:#43c6ac\">algoritmo de aprendizaje supervisado</span> que pertenece a la categoría de ensambles de algoritmos.\n",
    "\n",
    "Este modelo combina múltiples [árboles de decisión](pg201c_decisiontree.ipynb) para obtener un poder de predicción más robusto y generalmente más preciso que el que podría ofrecer un solo árbol de decisión.\n",
    "\n",
    "> #### **<span style=\"color:gold\">¿Qué son los ensambles de algoritmos?</span>**\n",
    "> Los ensambles de algoritmos son técnicas en el aprendizaje automático que combinan las predicciones de múltiples modelos para mejorar la robustez y la exactitud del modelo final.\n",
    "> \n",
    "> Funcionan bajo el principio de que un grupo de modelos débiles o moderadamente efectivos trabajando juntos puede proporcionar mejores resultados que un solo modelo.\n",
    ">\n",
    "> Estos métodos se clasifican generalmente en dos tipos principales:\n",
    "> - <span style=\"color:#43c6ac\">**Bagging (Bootstrap Aggregating)**: </span> <br>\n",
    "> Consiste en crear múltiples versiones de un predictor y entrenar cada uno con una muestra aleatoria de los datos. <br>\n",
    "> Luego, las predicciones se combinan mediante votación mayoritaria o promedio. **Random Forest es un ejemplo clásico de bagging**.\n",
    ">\n",
    "> - <span style=\"color:#43c6ac\">**Boosting**: </span> <br>\n",
    "> En este enfoque, los modelos se entrenan secuencialmente, cada uno tratando de corregir los errores del modelo anterior. <br>\n",
    "> Las predicciones se combinan ponderadamente. Ejemplos populares incluyen AdaBoost y Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba0f2d-b7cb-45f8-84d6-beaaa03285c4",
   "metadata": {},
   "source": [
    "Random Forest funciona de la siguiente manera:\n",
    "\n",
    "- <span style=\"color:lightgreen\">**Creación de árboles a partir de subconjuntos de datos:** </span> <br>\n",
    "En Random Forest, cada árbol se construye a partir de un subconjunto de datos seleccionados aleatoriamente. Este proceso se conoce como bootstrap sampling o muestreo con reemplazo. Cada subconjunto contiene una muestra aleatoria de observaciones y características, lo que ayuda a asegurar que los árboles sean diferentes y que el modelo final sea menos susceptible al sobreajuste.\n",
    "\n",
    "- <span style=\"color:lightgreen\">**Entrenamiento de múltiples árboles de decisión:** </span> <br>\n",
    "Una vez seleccionados los subconjuntos, se entrena un árbol de decisión en cada uno de ellos. Estos árboles son capaces de crecer a su máxima profundidad sin poda, lo que permite un aprendizaje profundo y detallado de los patrones en los datos.\n",
    "\n",
    "- <span style=\"color:lightgreen\">**Predicción mediante votación o promedio:** </span> <br>\n",
    "Para realizar predicciones, Random Forest aplica una estrategia de votación en el caso de clasificación (donde la clase predicha es la más votada por los árboles individuales) o un promedio en el caso de regresión (donde la predicción final es el promedio de las predicciones de todos los árboles).\n",
    "\n",
    "<center><img src=\"resources/random_forest.png\" alt=\"Random Forest\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396ab58-0b94-4a7f-bae9-2521a38d0f2d",
   "metadata": {},
   "source": [
    "***\n",
    "<span style=\"color:gold\">**Ventajas y limitaciones del modelo Random Forest** </span>\n",
    "\n",
    "- <span style=\"color:lightgreen\">**Robustez frente al sobreajuste:** </span> <br>\n",
    "A diferencia de los árboles de decisión individuales, que tienden a sobreajustar sus datos de entrenamiento especialmente cuando tienen muchas ramas, el método de ensamble de Random Forest generalmente ofrece un rendimiento que generaliza mejor a nuevos datos.\n",
    "\n",
    "- <span style=\"color:lightgreen\">**Manejo de grandes datasets con múltiples variables:** </span> <br>\n",
    "Puede manejar fácilmente datasets con miles de entradas y muchas variables sin necesidad de eliminar variables, gracias a que cada árbol se entrena con un subconjunto de características.\n",
    "\n",
    "- <span style=\"color:lightgreen\">**Importancia de las variables:** </span> <br>\n",
    "Random Forest proporciona una medida útil que indica cuáles son las variables más importantes en la predicción, lo que puede ser crucial para la interpretación en campos aplicados como la Geología.\n",
    "\n",
    "- <span style=\"color:orange\">**Complejidad del modelo:** </span> <br>\n",
    "Al ser un ensamble de muchos árboles, puede ser computacionalmente más intensivo y más difícil de interpretar en comparación con un solo árbol de decisión.\n",
    "\n",
    "- <span style=\"color:orange\">**Menor rendimiento en datos extremadamente desbalanceados:** </span> <br>\n",
    "Si bien maneja mejor el desbalance que otros modelos, en casos extremos puede requerir técnicas adicionales de balanceo de datos.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482af8a2-c7a8-48ff-a721-b6dd3b390fe0",
   "metadata": {},
   "source": [
    "<a id=\"parte-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfa10e-66e7-49a0-8d12-b301bc1531b6",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">**Random Forest en Python**</span>\n",
    "***\n",
    "\n",
    "Vamos a implementar un modelo de Random Forest para clasificación multiclase con información geoquímica, empezaremos importando las librerías y cargando el archivo `rocas.csv` ubicado en la carpeta `files`:\n",
    "> Este archivo contiene información geoquímica dividida en 9 columnas numéricas (`SiO2`, `Al2O3`, `CaO`, `Na2O`, `K2O`, `FeOT`, `MgO`, `MnO`, `TiO2`) y una columna categórica con la clasificación de cada muestra (`basalt`, `andesite`, `dacite`, `rhyolite`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f02fc-2b3f-4d45-b37a-aee5fdb4baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split   # Función para dividir los datos\n",
    "from sklearn.ensemble import RandomForestClassifier    # Modelo Random Forest para clasificación\n",
    "from sklearn.model_selection import cross_val_score    # Validación cruzada\n",
    "from sklearn.metrics import accuracy_score             # Métrica de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b1967-e2f5-44c5-b1ea-fa0ffcc4b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la información\n",
    "data = pd.read_csv(\"files/rocas.csv\")\n",
    "data.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66e1b2-ca1d-4f5e-a5cb-502ab12b1626",
   "metadata": {},
   "source": [
    "Ahora, crearemos las variables `X` e `y` para el entrenamiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34359ce-178a-42f0-a5e2-f08fed45a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, nos aseguramos que la tabla se encuentre ordenada de acuerdo a la columna objetivo\n",
    "data.sort_values(by=\"Nombre\", inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22ad99-bcfc-47d9-bb93-ad3940d970ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características (X) y etiqueta (y)\n",
    "X = data.drop(\"Nombre\", axis=1)\n",
    "y = data[\"Nombre\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68421db3-3b71-4054-9552-d9375255cf55",
   "metadata": {},
   "source": [
    "Usaremos la función `train_test_split` para seleccionar aleatoriamente los conjuntos de entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3fe91-92d1-43d5-96c0-c4d0a916f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be83d6-79ed-4fb8-a4e4-7d88b76c40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tamaño de X_train: {X_train.shape}\")\n",
    "print(f\"Tamaño de X_test: {X_test.shape}\")\n",
    "print(f\"Tamaño de y_train: {y_train.shape}\")\n",
    "print(f\"Tamaño de y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27652661-16ef-40b9-9b28-ac28cf0abf03",
   "metadata": {},
   "source": [
    "Ahora, crearemos el modelo de Random Forest usando la función `RandomForestClassifier` y los siguientes hiperparámetros:\n",
    "- `n_estimators`: se refiere al número de árboles de decisión. En este caso será igual a 25.\n",
    "- `max_depth`: se refiere a la profundidad máxima de cada árbol. En este caso será igual a 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e872718-e42a-43a0-8df5-d839e37cdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=25, max_depth=6, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ef436-f291-4b86-9a9f-952f5f886e56",
   "metadata": {},
   "source": [
    "Y entrenamos el modelo usando el método `fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c6b99-68ec-4e44-a596-1c7e10d130d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9de092-73b7-428e-91a2-3ba4c2247bac",
   "metadata": {},
   "source": [
    "Y generamos las predicciones del modelo para el entrenamiento y la prueba usando el método `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485730e5-ec0f-420e-9548-55e4a01a3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train) # Predicción con X_train\n",
    "y_test_pred = model.predict(X_test)   # Predicción con X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343222dc-559b-4d03-8ea4-9dc353e5d95b",
   "metadata": {},
   "source": [
    "Usando estas predicciones y la data real, evaluaremos la exactitud del modelo para el entrenamiento y la prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da8061-b171-4deb-8a25-7e6d000a71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy Score - Entrenamiento: {accuracy_score(y_true=y_train, y_pred=y_train_pred):.1%}\")\n",
    "print(f\"Accuracy Score - Prueba: {accuracy_score(y_true=y_test, y_pred=y_test_pred):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece57cd1-3b4e-4414-873c-18b9dd41016a",
   "metadata": {},
   "source": [
    "Notamos que la exactitud es cercana al 90% y es similar tanto para el entrenamiento como para la prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c346a0b-da32-4b9f-bf36-ba8897c52e5b",
   "metadata": {},
   "source": [
    "Ahora, tenemos que asegurar que el modelo generalice bien ante nuevos datos, y para esto usaremos validación cruzada.\n",
    "\n",
    "> <span style=\"color:gold\">**¿Qué es la validación cruzada?** </span>\n",
    ">\n",
    "> Validación cruzada (o Cross-Validation), es un método estadístico que consiste en dividir el conjunto de datos en varias particiones más pequeñas, y luego entrenar el modelo en varias de estas particiones mientras se usa el resto para probar el modelo.\n",
    ">\n",
    "> La forma más común es la <span style=\"color:#43c6ac\">validación cruzada Hold-out</span>, que usamos a través de la función `train_test_split`, y consiste en dividir el conjunto de datos en 2 partes: uno para el entrenamiento y otro para la prueba. Esta técnica es uno de los enfoques más simples y directos para validar la eficacia de un modelo de aprendizaje automático.\n",
    "> \n",
    "> Sin embargo, para obtener un resultado más confiable, es recomendable usar la <span style=\"color:#43c6ac\">validación cruzada k-fold</span> (k-Fold Cross-Validation):\n",
    "> - El conjunto de datos se divide aleatoriamente en `k` subconjuntos (o \"folds\") de aproximadamente igual tamaño.\n",
    "> - El modelo se entrena en `k-1` de estos folds, con el fold restante usado como conjunto de prueba.\n",
    "> - Este proceso se repite `k` veces, con cada uno de los `k` folds usado exactamente una vez como conjunto de prueba.\n",
    "> - La performance del modelo se promedia sobre los `k` tests para dar una estimación más completa de su eficacia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff580f2-2309-43ce-8229-00c1535512ac",
   "metadata": {},
   "source": [
    "Usaremos la función `cross_val_score` de Scikit-Learn para realizar la validación cruzada k-fold:\n",
    "> Los parámetros a usar son:\n",
    "> - `estimator`: es el modelo que evaluaremos.\n",
    "> - `X`: es el conjunto de features.\n",
    "> - `y`: es la columna target.\n",
    "> - `cv`: es el número de folds que realizará la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5eec53-00b2-45cb-9591-fd48df014a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un modelo de Random Forest para la validación cruzada\n",
    "cv_model = RandomForestClassifier(n_estimators=25, max_depth=6, random_state=5)\n",
    "\n",
    "# Aplicar validación cruzada con 5 folds\n",
    "cv_scores = cross_val_score(estimator=cv_model, X=X, y=y, cv=10)\n",
    "\n",
    "# Lista ordenada de resultados\n",
    "scores = list(cv_scores)\n",
    "scores = [round(s, 3) for s in scores]\n",
    "scores = sorted(scores, reverse=True)\n",
    "mean = cv_scores.mean() # Promedio de resultados\n",
    "\n",
    "# Mostrar los resultados de la validación cruzada\n",
    "print(\"Validación Cruzada - Random Forest\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Accuracy Score: {scores}\")\n",
    "print(f\"Accuracy Score promedio: {mean:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580a8e6-8c0f-4f50-bd9a-9ecc1b69e3ac",
   "metadata": {},
   "source": [
    "A través de la validación cruzada estándar, hemos observado que:\n",
    "\n",
    "- La exactitud de nuestro modelo fluctúa significativamente dependiendo del subconjunto de datos utilizado para el entrenamiento.\n",
    "- Esta variabilidad en la exactitud podría estar relacionada con la distribución desigual de las clases en algunos de los folds.\n",
    "- Específicamente, si ciertos folds contienen una proporción desproporcionada de una clase en particular, el modelo puede no desempeñarse tan bien debido a la falta de representación adecuada de las demás clases.\n",
    "\n",
    "Para abordar este problema, proponemos implementar un <span style=\"color:#43c6ac\">balanceo de clases</span>.\n",
    "> <span style=\"color:gold\">**¿En qué consiste el balanceo de clases?**</span> <br>\n",
    "> Esta técnica ajustará la selección de muestras en el conjunto de entrenamiento para asegurar que todas las clases estén equitativamente representadas. Al hacerlo, esperamos reducir la variabilidad en la exactitud entre diferentes folds y mejorar la generalización del modelo a nuevos datos.\n",
    "\n",
    "A continuación, desarrollaremos un script personalizado para la validación cruzada, asegurando que seleccionemos muestras de cada clase en una proporción similar a la del dataset total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99e8d9-ac79-4941-a6d7-aac68591660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada de 5 folds\n",
    "n_folds = 5\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for i in range(n_folds):\n",
    "    # Índice de las muestras de prueba\n",
    "    index = X.loc[i::n_folds].index  \n",
    "\n",
    "    # Modelo de Random Forest\n",
    "    cv_model = RandomForestClassifier(n_estimators=25, max_depth=6, random_state=5)\n",
    "    cv_model.fit(X.drop(index=index), y.drop(index=index)) # Entrenamiento\n",
    "\n",
    "    # Evaluación del modelo\n",
    "    train_pred = cv_model.predict(X.drop(index=index))     # Predicción en el entrenamiento\n",
    "    test_pred = cv_model.predict(X.loc[index])             # Predicción en la prueba\n",
    "    train_acc = accuracy_score(y.drop(index=index), train_pred)\n",
    "    test_acc = accuracy_score(y.loc[index], test_pred)\n",
    "    # Guardamos los resultados\n",
    "    train_scores.append(train_acc)\n",
    "    test_scores.append(test_acc)\n",
    "\n",
    "    # Total de muestras por clase en los datos de prueba\n",
    "    conteo = y.loc[index].value_counts()\n",
    "    total = len(index)\n",
    "    \n",
    "    # Resultados\n",
    "    print(f\"Validación cruzada - Fold {i+1}\")\n",
    "    print(\"-------------------------\")\n",
    "    for r, p in conteo.items():\n",
    "        print(f\"{r}: {p} ({p / total:.1%})\")\n",
    "    print(\"-------------------------\")\n",
    "    print(f\"Accuracy Score - Entrenamiento: {train_acc:.1%}\")\n",
    "    print(f\"Accuracy Score - Prueba: {test_acc:.1%}\\n\")\n",
    "\n",
    "train_mean = sum(train_scores) / len(train_scores)\n",
    "test_mean = sum(test_scores) / len(test_scores)\n",
    "print(\"\\nResumen de Validación Cruzada\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"Total de folds: {n_folds}\")\n",
    "print(f\"Accuracy Score Promedio - Entrenamiento: {train_mean:.1%}\")\n",
    "print(f\"Accuracy Score Promedio - Prueba: {test_mean:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc7113-4093-438b-b0ce-e32f1c239a1b",
   "metadata": {},
   "source": [
    "Hemos observado que, al mantener esta proporción en cada fold, la exactitud del modelo se mantiene consistente. <br>\n",
    "Esto sugiere que nuestro modelo tiene una exactitud aceptable y no sufre de sobreajuste ni subajuste.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c2795-0610-4199-bd67-a1167b0046ff",
   "metadata": {},
   "source": [
    "<a id=\"parte-3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd942d-3826-4351-918e-11f708627f14",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">**Evaluación del modelo**</span>\n",
    "***\n",
    "\n",
    "Ahora que hemos entrenado adecuadamente nuestro modelo de Random Forest, procederemos a evaluar su rendimiento utilizando algunas de las métricas de clasificación más comunes y esenciales. \n",
    "\n",
    "Estas métricas nos proporcionarán una visión clara de cómo el modelo clasifica cada categoría y nos permitirán identificar áreas potenciales para mejoras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34013c9c-1535-4e08-b1f5-cfa9b0c1f1e2",
   "metadata": {},
   "source": [
    "***\n",
    "#### 1. Matriz de confusión\n",
    "\n",
    "Empezaremos evaluando el modelo usando una **matriz de confusión**:\n",
    "\n",
    "> <span style=\"color:gold\">**¿Qué es una matriz de confusión?**</span>\n",
    ">\n",
    "> Una matriz de confusión es una tabla de dos dimensiones donde las filas representan las clases reales y las columnas representan las clases predichas por el modelo. Cada celda en la matriz muestra el número de predicciones hechas por el modelo para una clase en particular, comparado con la clase real.\n",
    ">\n",
    "> <span style=\"color:#43c6ac\">Esta visualización nos permite identificar rápidamente los errores de clasificación, particularmente aquellos donde el modelo confunde una clase con otra.</span>\n",
    ">\n",
    "> Las celdas en la diagonal principal de la matriz de confusión indican el número de predicciones correctas. Nuestro objetivo es maximizar estos valores para cada clase, indicando una alta exactitud.\n",
    ">\n",
    "> Por otra parte, las celdas fuera de la diagonal principal nos muestran los errores de clasificación. Estas entradas son particularmente valiosas para entender los tipos específicos de errores que está cometiendo el modelo, como confundir una clase con otra.\n",
    ">\n",
    "> A partir de la matriz, podemos calcular la sensibilidad (tasa de verdaderos positivos) y la especificidad (tasa de verdaderos negativos) para cada clase, lo que nos proporciona una vista más granular del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf948ada-4ae3-46db-a7f3-e995feaccd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix  # Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594424f0-10f1-4f51-8dc0-bd1223513db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para mapear valores numéricos en cada categoría\n",
    "class_mapping = {\n",
    "    # Clases\n",
    "    \"basalt\": 0, \n",
    "    \"andesite\": 1,\n",
    "    \"dacite\": 2,\n",
    "    \"rhyolite\": 3\n",
    "}\n",
    "\n",
    "# Función de transformación\n",
    "transform = np.vectorize(class_mapping.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81851e18-dbe0-450d-a3e8-782e7725ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(transform(y_test), transform(y_test_pred))\n",
    "\n",
    "# Matriz con valores transformados a porcentajes\n",
    "cm_pct = (cm.T / cm.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f120b9-054c-4a84-9c27-e2ccc094e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura principal\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Mapa de calor\n",
    "sns.heatmap(cm_pct, annot=True, fmt=\".1%\", cmap=\"Purples\", cbar=False,\n",
    "            square=\"equal\", linecolor=\"k\", linewidth=0.5,\n",
    "            xticklabels=[\"Basalto\", \"Andesita\", \"Dacita\", \"Riolita\"],\n",
    "            yticklabels=[\"Basalto\", \"Andesita\", \"Dacita\", \"Riolita\"])\n",
    "\n",
    "ax.spines[\"right\"].set_visible(True)\n",
    "ax.spines[\"bottom\"].set_visible(True)\n",
    "\n",
    "# Detalles de la figura\n",
    "ax.tick_params(left=False, bottom=False)\n",
    "\n",
    "# Texto\n",
    "ax.set_xlabel(\"Predicciones\")\n",
    "ax.set_ylabel(\"Valores Reales\")\n",
    "ax.set_title(\"Random Forest - Matriz de Confusión\", y=1.02, fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e449911-0d3c-4b6c-8a3e-210d6b4bb93a",
   "metadata": {},
   "source": [
    "A partir de la matriz de confusión, observamos los siguientes resultados:\n",
    "\n",
    "- La mayoría de las muestras de `Basalto` han sido clasificadas correctamente (93%). Sin embargo, un 6% se ha clasificado como `Andesita`, y menos del 1% como `Dacita` y `Riolita`.\n",
    "\n",
    "- La mayoría de las muestras de `Andesita` se han clasificado correctamente (89%). No obstante, un 5% se ha identificado erróneamente como `Basalto`, un 4% como `Dacita`, y menos del 1% como `Riolita`.\n",
    "\n",
    "- Un 80% de las muestras de `Dacita` han sido clasificadas correctamente, lo cual es un porcentaje aceptable. Sin embargo, hay un 10% clasificado erróneamente como `Andesita` y un 9% como `Riolita`. Menos del 1% ha sido clasificado como Basalto.\n",
    "\n",
    "- La mayoría de las muestras de `Riolita` (91%) se han clasificado correctamente. Un 7% se ha clasificado como `Dacita`, y menos del 1% como `Andesita` y `Basalto`.\n",
    "\n",
    "<span style=\"color:#43c6ac\">En conclusión</span>, estos resultados de la matriz de confusión revelan que nuestro modelo de Random Forest es bastante eficaz en la clasificación de muestras de Basalto, Riolita y, en menor medida, Andesita, demostrando altas tasas de exactitud. No obstante, la clasificación de Dacita muestra un porcentaje más bajo de exactitud, indicando áreas potenciales para mejorar la exactitud del modelo en esta categoría. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65aa797-781c-4ac7-b17d-4b2e5cb1a4d6",
   "metadata": {},
   "source": [
    "***\n",
    "#### 2. Precisión, sensibilidad y F1-score:\n",
    "\n",
    "Usando los resultados de la matriz de confusión, podemos evaluar la <span style=\"color:#43c6ac\">precisión</span>, <span style=\"color:#43c6ac\">sensibilidad</span> y <span style=\"color:#43c6ac\">F1-score</span> del modelo:\n",
    "\n",
    "> <span style=\"color:gold\">**¿Qué es la Precisión (Precision)?**</span>\n",
    ">\n",
    "> La precisión mide la exactitud de las predicciones positivas del modelo. Es la proporción de verdaderos positivos (TP) entre todas las predicciones positivas realizadas (es decir, la suma de verdaderos y falsos positivos, TP + FP).\n",
    "> \n",
    "> $$\n",
    "\\text{Precisión} = \\frac{\\text{Verdaderos Positivos (TP)}}{\\text{Verdaderos Positivos (TP) + Falsos Positivos (FP)}}\n",
    "$$\n",
    ">\n",
    "> La precisión es especialmente útil en aplicaciones geológicas donde las consecuencias de los falsos positivos son significativas. Por ejemplo, en la exploración minera, una alta precisión en la identificación de minerales indicativos de la presencia de oro significa que se minimizan los esfuerzos y costos al explorar y procesar material que realmente no contiene oro. En este contexto, una alta precisión asegura que las muestras clasificadas como indicativas de depósitos valiosos realmente contienen los minerales de interés.\n",
    "\n",
    "> <span style=\"color:gold\">**¿Qué es el Recall (Sensitivity)?**</span>\n",
    ">\n",
    "> El recall mide la capacidad del modelo para detectar todas las instancias positivas relevantes en el dataset. Es la proporción de verdaderos positivos entre los positivos reales (es decir, la suma de verdaderos positivos y falsos negativos, TP + FN).\n",
    ">\n",
    "> $$\n",
    "\\text{Recall} = \\frac{\\text{Verdaderos Positivos (TP)}}{\\text{Verdaderos Positivos (TP) + Falsos Negativos (FN)}}\n",
    "$$\n",
    ">\n",
    "> Esta métrica es crucial cuando es importante detectar todos los casos positivos de una característica geológica específica. Por ejemplo, en la evaluación de riesgos geológicos como deslizamientos de tierra o actividad volcánica, se busca un recall alto para asegurar que todas las áreas potencialmente peligrosas sean identificadas. Un alto recall en este contexto significa que el modelo minimiza el riesgo de pasar por alto áreas que podrían representar una amenaza significativa para las infraestructuras o la vida humana.\n",
    "\n",
    "> <span style=\"color:gold\">**¿Qué es el F1 Score?**</span>\n",
    ">\n",
    "> El F1 Score es la media armónica de la precisión y el recall, proporcionando un balance entre estas dos métricas. Es especialmente útil cuando las clases están desequilibradas.\n",
    "> \n",
    "> $$\n",
    "F1 = 2 \\times \\frac{\\text{Precisión} \\times \\text{Recall}}{\\text{Precisión} + \\text{Recall}}\n",
    "$$\n",
    ">\n",
    "> El F1 Score es útil cuando se necesita un equilibrio entre precisión y recall, lo cual es común en la geología cuando las clases de interés están desequilibradas. Por ejemplo, en estudios ambientales para la identificación de zonas contaminadas, algunas contaminaciones pueden ser raras pero críticas de detectar. El F1 Score ayuda a balancear la necesidad de precisar correctamente las áreas contaminadas (precisión) con la necesidad de identificar todas las áreas potencialmente contaminadas (recall), asegurando una gestión efectiva y eficiente de las intervenciones medioambientales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d6957-e22c-4c2e-a9aa-b516ff34e786",
   "metadata": {},
   "source": [
    "<center><img src=\"resources/precision_recall_f1.jpg\" alt=\"Classification metrics\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2509ad11-3667-4d96-938d-bd6d2858572c",
   "metadata": {},
   "source": [
    "Usaremos la función `classification_report` para mostrar todas estas métricas:\n",
    "> La columna `support` hace referencia al total de datos en `y_test` para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bc79d-ce46-432f-bfdb-1fc9e73de0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a922b34-dccd-438b-ae3a-eeb455d434bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular y mostrar precisión, recall y F1 score para cada clase\n",
    "report = classification_report(y_test, y_test_pred, target_names=model.classes_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1b8c2-9509-4aaa-89e6-1185e054f9d0",
   "metadata": {},
   "source": [
    "El informe de clasificación muestra que el modelo de Random Forest tiene un buen desempeño en la clasificación de los cuatro tipos de roca, con una precisión general del 90%.\n",
    "\n",
    "Las métricas clave para cada tipo de roca son:\n",
    "- `Basalto`: muestra excelentes resultados con una precisión del 95%, un recall del 94%, y un F1-score de 0.94.\n",
    "- `Andesita`: tiene una precisión del 86% y un recall del 89%, con un F1-score de 0.88.\n",
    "- `Dacita`: presenta un rendimiento algo más bajo, con una precisión del 83%, un recall del 80%, y un F1-score de 0.82.\n",
    "- `Riolita`: tiene una alta precisión del 91% y un recall del 92%, con un F1-score de 0.91.\n",
    "\n",
    "<span style=\"color:#43c6ac\">En conclusión</span>, el modelo muestra un excelente desempeño en la clasificación de tipos de roca, con altas puntuaciones de precisión, recall y F1-score para todas las clases. Basalto y Riolita tienen puntuaciones particularmente altas, indicando un equilibrio ideal entre precisión y capacidad de detección. Andesita y Dacita, aunque ligeramente más bajos, muestran un rendimiento robusto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca8e680-ae01-4ade-b0e5-8e477f2d78a8",
   "metadata": {},
   "source": [
    "***\n",
    "#### 3. Curva ROC y AUC\n",
    "\n",
    "A continuación, evaluaremos el modelo usando la **curva ROC y AUC**:\n",
    "\n",
    "> <span style=\"color:gold\">**¿Qué es la curva ROC?**</span>\n",
    ">\n",
    "> La Curva ROC (Receiver Operating Characteristic) es una herramienta gráfica utilizada para evaluar la capacidad de un sistema de clasificación binaria (y extendida a multiclase) para discriminar entre las clases positivas y negativas.\n",
    ">\n",
    "> El eje x representa la Tasa de Falsos Positivos (FPR, False Positive Rate), que es la proporción de negativos reales que se clasificaron incorrectamente como positivos. El eje y representa la Tasa de Verdaderos Positivos (TPR, True Positive Rate), que es la proporción de positivos reales que se clasificaron correctamente.\n",
    ">\n",
    "> A medida que se ajusta el umbral de decisión del clasificador (por ejemplo, ajustando la probabilidad de corte para la clasificación), se calculan TPR y FPR para cada valor del umbral, y se grafican para formar la curva ROC.\n",
    "\n",
    "> <span style=\"color:gold\">**¿Y qué es el AUC?**</span>\n",
    ">\n",
    "> El Área Bajo la Curva (Area Under Curve) es una métrica que proporciona una medida agregada del rendimiento de un modelo a lo largo de todos los umbrales de clasificación. Es el área bajo la curva ROC.\n",
    "> \n",
    "> Un AUC de 1.0 representa un modelo perfecto que clasifica correctamente todos los positivos y negativos. Un AUC de 0.5 sugiere un rendimiento no mejor que el azar. Cuanto más cerca esté el AUC de 1, mejor será el modelo en la clasificación entre las clases positiva y negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9d6d7-9ee4-4746-8481-a71e5ed5a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score  # Curva ROC y AUC\n",
    "from sklearn.preprocessing import label_binarize           # Para procesar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66618db5-6ca1-448a-a0dd-17a1acc8e600",
   "metadata": {},
   "source": [
    "Empezaremos generando las probabilidades de las clases para cada instancia en `X_test` usando el método `predict_proba`:\n",
    "\n",
    "> Las probabilidades de clase obtenidas a través del método `predict_proba` de un modelo de clasificación son estimaciones numéricas que indican la confianza o la probabilidad de que una determinada muestra pertenezca a cada una de las clases posibles en un problema de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c65b3c-ac60-4521-98fd-f352907ef36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades de cada clase\n",
    "y_scores = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4c384-456f-4a65-a0e7-c2d22650720c",
   "metadata": {},
   "source": [
    "A continuación, binarizaremos las clases para poder calcular la curva ROC y el área bajo la curva (AUC):\n",
    "\n",
    "> <span style=\"color:gold\">**¿En qué consiste la binarización de las clases?**</span>\n",
    ">\n",
    "> Binarizar las clases significa transformar las etiquetas de las clases en un formato binario (0 o 1) para facilitar ciertos tipos de análisis y procesos computacionales, especialmente en problemas que involucran clasificación multiclase o en situaciones donde solo interesa distinguir una clase de todas las demás.\n",
    ">\n",
    "> Por ejemplo, consideremos que tenemos cuatro clases: `basalt`, `andesite`, `dacite`, y `rhyolite`. Al binarizar una muestra de andesite, la representación resultante sería `[0, 1, 0, 0]`. En este vector binario, cada posición representa una clase específica, y el valor 1 indica la pertenencia de la muestra a la clase `andesite`, mientras que los valores 0 indican que no pertenece a las otras clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac4b03-25b0-4513-884b-5823b5d64590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizar las etiquetas si tienes más de dos clases\n",
    "y_test_binarized = label_binarize(y_test, classes=model.classes_)\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "classes = model.classes_\n",
    "\n",
    "# Calcular la curva ROC y AUC para cada clase\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "for i in range(n_classes):\n",
    "    # Puntos para plotear la curva ROC\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_scores[:, i])\n",
    "    # Cálculo del AUC\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6097a7-352d-4fe0-bf06-7b9872606c1a",
   "metadata": {},
   "source": [
    "Y ahora, graficaremos la curva ROC para todas las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ce369-134d-4584-a7d7-d34eb60f1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paleta de colores para el gráfico\n",
    "palette = {\"basalt\": \"blue\",\n",
    "           \"andesite\": \"green\",\n",
    "           \"dacite\": \"orange\",\n",
    "           \"rhyolite\": \"red\"\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5c5df1-c002-4540-9cd8-904da839cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura principal\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Gráfico de líneas\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], c=palette[classes[i]], lw=1, alpha=0.8,\n",
    "            label=f\"{classes[i]:<9} (AUC$=${roc_auc[i]:.3f})\")\n",
    "\n",
    "# Línea diagonal\n",
    "ax.plot([0, 1], [0, 1], \"k--\")\n",
    "\n",
    "# Límites y texto\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel(\"Tasa de Falsos Positivos\")\n",
    "ax.set_ylabel(\"Tasa de Verdaderos Positivos\")\n",
    "ax.set_title(\"Random Forest - Curvas ROC\")\n",
    "\n",
    "# Leyenda\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c4b33-ce28-4849-bf9f-f66e3fb84ba8",
   "metadata": {},
   "source": [
    "Observando las curvas ROC y el AUC notamos lo siguiente:\n",
    "\n",
    "- `Basalto` (AUC = 0.991): este valor casi perfecto indica que el modelo es excepcionalmente bueno para clasificar basalto frente a no basalto. Prácticamente todas las decisiones sobre si una muestra es basalto o no son correctas.\n",
    "- `Andesita` (AUC = 0.970): también es un resultado muy alto, mostrando que el modelo distingue eficazmente entre andesita y las otras clases. La probabilidad de error en la clasificación de andesita es muy baja.\n",
    "- `Dacita` (AUC = 0.966): aunque ligeramente más bajo que los de basalto y andesita, este valor sigue siendo alto, lo que significa que el modelo es muy capaz de identificar correctamente dacita frente a las otras rocas.\n",
    "- `Riolita` (AUC = 0.989): similar al basalto, este valor alto muestra que el modelo es muy preciso al clasificar muestras de riolita, con muy pocos errores en términos de falsos positivos y falsos negativos.\n",
    "\n",
    "<span style=\"color:#43c6ac\">En conclusión</span>, los valores de AUC son excepcionalmente altos para todas las clases, con el Basalto y la Riolita casi perfectos. Esto indica que el modelo tiene una excelente capacidad para diferenciar entre cada clase y las no clases. Los altos valores de AUC corroboran la habilidad del modelo para manejar bien tanto los verdaderos positivos como los falsos positivos, lo que es esencial en un entorno geológico práctico.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e5ab04-b2da-418a-b13a-e135d64a5a1c",
   "metadata": {},
   "source": [
    "<a id=\"parte-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52a146-4612-47db-acef-9ff1d924d65d",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">**Importancia de las características**</span>\n",
    "***\n",
    "\n",
    "Usaremos ahora el modelo de Random Forest entrenado para evaluar la <span style=\"color:#43c6ac\">importancia de las características</span> con la finalidad de determinar que variables son las más importantes en el modelo.\n",
    " \n",
    "> <span style=\"color:gold\">**¿Qué es la Importancia de las Características (Feature Importances)?** </span>\n",
    "> \n",
    "> Cuando se entrena un modelo de Random Forest, el algoritmo mide la importancia de cada variable evaluando cuánto mejora el rendimiento del modelo cada vez que se utiliza una característica en los árboles de decisión.\n",
    "> \n",
    "> Esencialmente, esta métrica se calcula a partir de la mejora promedio en la exactitud o pureza de los nodos que usan la característica, ponderada por la probabilidad de alcanzar ese nodo (que es proporcional al número de muestras que llegan al nodo).\n",
    "\n",
    "En el análisis de datos geoquímicos, comprender qué elementos influyen más en la clasificación de las rocas es crucial. Las características más importantes revelan qué elementos son más distintivos entre diferentes tipos de rocas volcánicas, proporcionando insights valiosos sobre los procesos geológicos que formaron estas rocas. Estos insights pueden ser esenciales para aplicaciones prácticas como la exploración mineral o la investigación geológica.\n",
    "\n",
    "Para obtener las importancias, usaremos el atributo `feature_importances_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f8dc06-d77c-49b1-8fb4-62e0f117cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las importancias de las características del modelo\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Extraemos los nombres de las variables\n",
    "features = X.columns\n",
    "\n",
    "# Unimos ambos conjuntos y los ordenamos\n",
    "f_importances = pd.Series(importances, index=features)\n",
    "f_importances.sort_values(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a65e9-dab0-460e-b681-c1caec6a8702",
   "metadata": {},
   "source": [
    "Empezaremos usando `print` para mostrar las importancias de cada columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6c5cc-68d2-4b92-a1ae-bc9c9c959c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las importancias de cada columna\n",
    "print(\"Importancias del modelo\")\n",
    "print(\"------------------------\")\n",
    "for col, imp in f_importances.items():\n",
    "    print(f\"{col:<5}: {imp:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0e291-2c09-41cf-95df-cfbd5799ac47",
   "metadata": {},
   "source": [
    "Ahora, visualizaremos estas importancias con un gráfico para comprender mejor qué variables tienen el mayor impacto en nuestro modelo.\n",
    "\n",
    "Este análisis es crucial para interpretar la efectividad del modelo y para tomar decisiones informadas sobre qué aspectos podrían requerir más atención en futuras recolecciones de datos o ajustes del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979fe89a-e8e3-4e3b-aea6-8fee61579384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gráfico de barras\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Diagrama de barras horizontal\n",
    "bars = ax.barh(f_importances.index, f_importances.values, color=\"skyblue\", edgecolor=\"k\")\n",
    "\n",
    "# Añadir texto de porcentaje a cada barra\n",
    "for bar in bars:\n",
    "    width = bar.get_width()  # Ancho de la barra (el valor numérico de importancia)\n",
    "    label_x_pos = width + 0.01  # Posición X para el texto (un poco a la derecha de la barra)\n",
    "    ax.text(label_x_pos, bar.get_y() + bar.get_height()/2, f\"{width:.1%}\", va=\"center\")\n",
    "\n",
    "# Invertir el eje Y para tener la característica más importante arriba\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Texto\n",
    "ax.set_xlabel(\"Importancia (%)\")\n",
    "ax.set_ylabel(\"Feature\")\n",
    "ax.set_title(\"Importancia de las Características - Random Forest\")\n",
    "\n",
    "# Remover cuadro y ticks\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "ax.yaxis.set_ticks_position(\"none\") \n",
    "ax.xaxis.set_ticks_position(\"none\")\n",
    "\n",
    "# Ticks del eje X\n",
    "xticks = ax.get_xticks()\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels([str(np.round(100 * s, 0)) for s in xticks])\n",
    "ax.set_xlim(xticks.min(), xticks.max() + 0.05)\n",
    "\n",
    "# Grilla\n",
    "ax.grid(linestyle=\"--\", linewidth=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c0922-152f-4659-a40e-e02784af55e9",
   "metadata": {},
   "source": [
    "En base al gráfico de importancias, podemos interpretar lo siguiente:\n",
    "\n",
    "- Sílice (`SiO2`): <br>\n",
    "Con una importancia del 44.8%, el `SiO2` es crítico para determinar el tipo de roca volcánica. Su alta importancia refleja su papel en la definición de la composición de las rocas, donde las variaciones en el contenido de `SiO2` pueden indicar diferencias significativas en la viscosidad del magma. Esto, a su vez, afecta el tipo de erupción volcánica y las características de las rocas formadas, como la diferenciación entre riolita, dacita, andesita y basalto.\n",
    "\n",
    "- Óxido de Calcio (`CaO`): <br>\n",
    "Con un 16.9% de importancia, el `CaO` es relevante para comprender las condiciones de formación de las rocas, ya que influye en la alteración de minerales y en las reacciones químicas durante la cristalización del magma. Un alto contenido de `CaO` puede estar asociado con rocas más básicas como el basalto.\n",
    "\n",
    "- Óxido Total de Hierro (`FeOT`): <br>\n",
    "Con una importancia del 12.5%, el `FeOT` es un indicativo de las condiciones redox del magma, lo cual es fundamental para determinar el ambiente geológico y las propiedades magnéticas de las rocas volcánicas.\n",
    "\n",
    "- Óxido de Magnesio (`MgO`) y Dióxido de Titanio (`TiO2`): <br>\n",
    "Con importancias del 10.1% y 8.7% respectivamente, estos elementos son indicativos de la profundidad y el grado de fusión del manto del que proviene el magma. `MgO`, en particular, está asociado con magmas derivados de fuentes mantélicas más profundas, mientras que el `TiO2` puede indicar procesos de cristalización fraccionada o acumulación de minerales titano-magnetita en el magma.\n",
    "\n",
    "- Óxido de Aluminio (`Al2O3`), Óxido de Manganeso (`MnO`), Óxido de Potasio (`K2O`), y Óxido de Sodio (`Na2O`): <br>\n",
    "Con importancias relativamente bajas (3.0%, 1.9%, 1.8%, y 0.4% respectivamente), estos elementos aún juegan roles específicos en petrología. `Al2O3` puede indicar la presencia de feldespatos y otros minerales alumino-silicatos, que son cruciales para clasificar las rocas ígneas. `K2O` y `Na2O` están relacionados con la mineralogía alcalina de las rocas y pueden indicar procesos geológicos como la alteración hidrotermal o la diferenciación magmática. `MnO`, aunque menos influyente, puede ser útil para rastrear procesos de oxidación y condiciones ambientales durante la formación de la roca.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb9494-cc49-4043-87bf-52990ed0e7bd",
   "metadata": {},
   "source": [
    "A continuación, visualizaremos la agrupación de los datos real versus la predicción del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b78121-a677-42a5-b625-bf480a461e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrolite.plot import pyroplot\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5379e64-bbb9-44e9-b905-41cf5d6305ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo sobre todos los datos\n",
    "y_pred = model.predict(X)\n",
    "data[\"pred\"] = y_pred\n",
    "data[\"Na2O + K2O\"] = data[\"Na2O\"] + data[\"K2O\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55885e75-c90d-407f-a641-144a7afa385d",
   "metadata": {},
   "source": [
    "Usaremos un diagrama ternario AFM para visualizar los datos:\n",
    "\n",
    "> <span style=\"color:gold\">**¿Qué es un diagrama AFM?** </span>\n",
    ">\n",
    "> Un diagrama AFM es una herramienta gráfica utilizada en geoquímica y petrología para clasificar y entender la composición química de las rocas ígneas, especialmente en lo que respecta a su evolución magmática. El nombre \"AFM\" deriva de las iniciales de los óxidos de Aluminio (`Al2O3`), Hierro (`FeO`), y Magnesio (`MgO`).\n",
    "> \n",
    "> Este diagrama es particularmente útil para explorar las tendencias en la diferenciación magmática y la cristalización fraccionada dentro de una serie de rocas ígneas.\n",
    ">\n",
    "> En el diagrama, cada punto dentro del triángulo representa una muestra de roca con una composición específica de estos tres componentes. La posición de un punto dentro del triángulo puede dar información sobre la fuente del magma, el proceso de cristalización y la temperatura de formación de la roca.\n",
    ">\n",
    "> Por ejemplo, un desplazamiento hacia el vértice `FeO` podría indicar una oxidación más alta o un ambiente de formación diferente en comparación con aquellos muestras que se agrupan cerca del vértice `MgO`, que podría indicar un grado más alto de cristalización de olivino, por ejemplo.\n",
    ">\n",
    "> Algunos usos principales de este diagrama son:\n",
    "> - Visualización de las tendencias de diferenciación magmática en series ígneas, mostrando cómo las fracciones de alúmina, hierro y magnesio varían a medida que el magma evoluciona.\n",
    ">\n",
    "> - Clasificación de las rocas en series toleíticas, calco-alcalinas, entre otras, basándose en sus trayectorias de evolución dentro del diagrama.\n",
    ">\n",
    "> - Los cambios en las trayectorias de las muestras en el diagrama pueden indicar distintos procesos geológicos, como la contaminación del magma, la mezcla magmática, o la cristalización fraccionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d082195-05d0-4aef-9bf9-273de74d427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura principal\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Subconjunto\n",
    "sample = data.sample(2000)\n",
    "\n",
    "# Diagrama de dispersión\n",
    "scatter1 = sample[[\"FeOT\", \"Na2O + K2O\", \"MgO\"]].pyroplot.scatter(ax=axs[0], c=sample[\"Nombre\"].apply(palette.get),\n",
    "                                                            alpha=0.5, s=8, marker=\".\")\n",
    "scatter2 = sample[[\"FeOT\", \"Na2O + K2O\", \"MgO\"]].pyroplot.scatter(ax=axs[1], c=sample[\"pred\"].apply(palette.get),\n",
    "                                                            alpha=0.5, s=8, marker=\".\")\n",
    "\n",
    "# Títulos\n",
    "scatter1.set_title(\"Datos Originales\", y=1.2)\n",
    "scatter2.set_title(\"Predicción del modelo\", y=1.2)\n",
    "fig.suptitle(\"Clasificación de rocas volcánicas - Random Forest\")\n",
    "\n",
    "# Detalles adicionales\n",
    "for sc in [scatter1, scatter2]:\n",
    "    # Grilla\n",
    "    sc.grid(axis=\"both\", linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "# Leyenda\n",
    "# Crear elementos de leyenda\n",
    "legend_elements = [mpatches.Patch(color=color, label=label) for label, color in palette.items()]\n",
    "\n",
    "# Añadir leyenda al lado derecho de la figura\n",
    "fig.legend(handles=legend_elements, bbox_to_anchor=(0.44, 0.85), title=\"Clases\", frameon=True,\n",
    "           fontsize=8, edgecolor=\"k\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c0b75-05d1-4b3f-b575-ca0412c3539c",
   "metadata": {},
   "source": [
    "La alta precisión del 90% del modelo se refleja en la similitud visual entre los dos gráficos. La mayoría de las predicciones coinciden con los datos originales, lo que indica que el modelo es capaz de capturar las características distintivas de cada clase de roca volcánica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d63a5e-76b2-4922-a28e-73e644208e67",
   "metadata": {},
   "source": [
    "<a id=\"parte-5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b31fb-30f0-47ff-9805-9ae842628992",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightgreen\">**En conclusión...**</span>\n",
    "***\n",
    "\n",
    "- El modelo de Random Forest alcanzó una alta precisión en la clasificación, demostrando su eficacia para identificar correctamente diferentes clases basadas en los datos proporcionados. Esta alta precisión refleja la robustez del modelo para manejar conjuntos de datos con múltiples variables y proporcionar resultados consistentes.\n",
    "\n",
    "- Además de la alta precisión en la clasificación, el modelo <span style=\"color:#43c6ac\">ofrece una visión detallada de la importancia de los diferentes características</span>. La importancia relativa de las variables puede ser visualizada claramente, lo que permite focalizar estudios en los componentes más influyentes.\n",
    "\n",
    "- El enfoque basado en machine learning facilita la automatización de los análisis de datos geológicas, aumentando la eficiencia y precisión de estos análisis. La capacidad de realizar validaciones cruzadas y ajustes de hiperparámetros asegura que el modelo esté bien calibrado y adaptado a los datos específicos de cada estudio.\n",
    "\n",
    "- La integración de este modelo con otros métodos de machine learning puede mejorar aún más la precisión y la interpretación de los resultados. Además, la inclusión de más datos relevantes podría mejorar la capacidad del modelo para generalizar a diferentes condiciones y tipos de datos.\n",
    "\n",
    "- Finalmente, la aplicabilidad de este modelo puede extenderse a otras tareas en Geología donde la identificación precisa de diferentes tipos y categorías es crucial para la toma de decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139675be-ad4b-4ac7-a77d-948e16d45bea",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
