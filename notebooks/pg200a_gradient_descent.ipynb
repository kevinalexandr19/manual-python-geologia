{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218843b9-ca99-43bd-84a6-de5a397826df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div align=\"center\">\n",
    "    <span style=\"font-size:30px\">\n",
    "        <strong>\n",
    "            <!-- Símbolo de Python -->\n",
    "            <img\n",
    "                src=\"https://cdn3.emoji.gg/emojis/1887_python.png\"\n",
    "                style=\"margin-bottom:-5px\"\n",
    "                width=\"30px\" \n",
    "                height=\"30px\"\n",
    "            >\n",
    "            <!-- Título -->\n",
    "            Python para Geólogos\n",
    "            <!-- Versión -->\n",
    "            <img \n",
    "                src=\"https://img.shields.io/github/release/kevinalexandr19/manual-python-geologia.svg?style=flat&label=&color=blue\"\n",
    "                style=\"margin-bottom:-2px\" \n",
    "                width=\"40px\"\n",
    "            >\n",
    "        </strong>\n",
    "    </span>\n",
    "    <br>\n",
    "    <span>\n",
    "        <!-- Github del proyecto -->\n",
    "        <a href=\"https://github.com/kevinalexandr19/manual-python-geologia\" target=\"_blank\">\n",
    "            <img src=\"https://img.shields.io/github/stars/kevinalexandr19/manual-python-geologia.svg?style=social&label=Github Repo\">\n",
    "        </a>\n",
    "        &nbsp;&nbsp;\n",
    "        <!-- Licencia -->\n",
    "        <img src=\"https://img.shields.io/github/license/kevinalexandr19/manual-python-geologia.svg?color=forestgreen\">\n",
    "        &nbsp;&nbsp;\n",
    "        <!-- Release date -->\n",
    "        <img src=\"https://img.shields.io/github/release-date/kevinalexandr19/manual-python-geologia?color=gold\">\n",
    "    </span>\n",
    "    <br>\n",
    "    <span>\n",
    "        <!-- Perfil de LinkedIn -->\n",
    "        <a target=\"_blank\" href=\"https://www.linkedin.com/in/kevin-alexander-gomez/\">\n",
    "            <img src=\"https://img.shields.io/badge/-Kevin Alexander Gomez-5eba00?style=social&logo=linkedin\">\n",
    "        </a>\n",
    "        &nbsp;&nbsp;\n",
    "        <!-- Perfil de Github -->\n",
    "        <a target=\"_blank\" href=\"https://github.com/kevinalexandr19\">\n",
    "            <img src=\"https://img.shields.io/github/followers/kevinalexandr19.svg?style=social&label=kevinalexandr19&maxAge=2592000\">\n",
    "        </a>\n",
    "    </span>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e5441-fc24-4bde-86fc-57eaf086f1b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:lightgreen; font-size:25px\">**PG200 - Fundamentos de Machine Learning**</span>\n",
    "\n",
    "Bienvenido al curso!!!\n",
    "\n",
    "Vamos a revisar las bases del <span style=\"color:gold\">aprendizaje automático</span> y su aplicación en Geología. <br>\n",
    "Es necesario que tengas un conocimiento previo en programación con Python, álgebra lineal, estadística y geología.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bc7e5-bf21-47ab-8c01-ac9eba94266e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:gold; font-size:20px\">**Descenso del Gradiente** </span>\n",
    "***\n",
    "\n",
    "1. [¿En qué consiste el Descenso del Gradiente?](#parte-1)\n",
    "2. [Ejemplos de optimización](#parte-2)\n",
    "3. [Optimización de parámetros en modelos lineales](#parte-3)\n",
    "4. [En conclusión...](#parte-4)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11246783-8f9b-4cf1-8ff7-ad6eba54d723",
   "metadata": {},
   "source": [
    "<a id=\"parte-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06fa7e-c964-4eb3-9a52-4d44359d016e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightgreen\">**¿En qué consiste el Descenso del Gradiente?**</span>\n",
    "***\n",
    "\n",
    "El descenso del gradiente (Gradient Descent) es un algoritmo de optimización fundamentalmente utilizado en Machine Learning para minimizar una función de coste. Su objetivo es <span style=\"color:#43c6ac\">encontrar los valores de los parámetros del modelo que minimicen esta función</span>, lo cual se traduce en mejorar la precisión y el rendimiento del modelo.\n",
    "\n",
    "> El descenso del gradiente se basa en la idea de ajustar iterativamente los parámetros del modelo en la dirección opuesta al gradiente de la función de coste con respecto a esos parámetros. El gradiente indica la dirección de la pendiente más pronunciada de la función de coste, y al moverse en la dirección opuesta, el algoritmo busca el mínimo de la función."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253c1f2-f0d1-4e11-ae19-8733cb9ec0d1",
   "metadata": {},
   "source": [
    "Los pasos para ejecutar el algoritmo de Descenso del Gradiente son:\n",
    "\n",
    "1. <span style=\"color:#43c6ac\">Inicialización</span>: los parámetros del modelo se inicializan, generalmente con valores aleatorios.\n",
    "\n",
    "2. <span style=\"color:#43c6ac\">Cálculo del gradiente</span>: para cada iteración, se calcula el gradiente de la función de coste con respecto a los parámetros del modelo. Este gradiente se basa en la derivada parcial de la función de coste.\n",
    "\n",
    "3. <span style=\"color:#43c6ac\">Actualización de parámetros</span>: los parámetros del modelo se actualizan restando el producto del gradiente y una tasa de aprendizaje ($\\alpha$):\n",
    "    <br>\n",
    "    <center>\n",
    "        $ \\Large \\theta = \\theta - \\alpha \\cdot \\nabla J(\\theta) $\n",
    "    </center>\n",
    "    \n",
    "    > Donde:\n",
    "    > - $\\theta$ son los parámetros del modelo.\n",
    "    > - $\\alpha$ es la tasa de aprendizaje, un hiperparámetro que determina el tamaño del paso de ajuste.\n",
    "    > - $\\nabla J(\\theta)$ es el gradiente de la función de coste $J(\\theta)$. \n",
    "\n",
    "4. <span style=\"color:#43c6ac\">Repetición</span>: los pasos 2 y 3 se repiten hasta que el algoritmo converge, es decir, hasta que las actualizaciones de los parámetros son lo suficientemente pequeñas o se alcanza un número máximo de iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476ad97-78b8-41ce-b919-585c8799875d",
   "metadata": {},
   "source": [
    "Existen diferentes versiones del algoritmo, entre las más populares están:\n",
    "\n",
    "- <span style=\"color:lightgreen\">Batch Gradient Descent:</span> <br>\n",
    "  Utiliza todo el conjunto de datos para calcular el gradiente. Es preciso pero puede ser muy lento y computacionalmente costoso para grandes       conjuntos de datos.\n",
    "\n",
    "- <span style=\"color:lightgreen\">Stochastic Gradient Descent (SGD):</span> <br>\n",
    "  Actualiza los parámetros para cada ejemplo de entrenamiento individual. Es mucho más rápido y puede converger más rápidamente, pero puede ser menos preciso debido a la alta varianza en las actualizaciones.\n",
    "\n",
    "- <span style=\"color:lightgreen\">Mini-batch Gradient Descent:</span> <br>\n",
    "  Combina los enfoques anteriores, usando pequeños lotes de datos (mini-batches) para calcular el gradiente en cada iteración. Ofrece un buen balance entre velocidad y precisión.\n",
    "\n",
    "- <span style=\"color:lightgreen\">Adam (Adaptive Moment Estimation):</span> <br>\n",
    "  Mejora significativamente el algoritmo de Descenso de Gradiente con medias móviles de primer y segundo orden de los gradientes y correcciones de sesgo. Estas mejoras permiten tener tasas de aprendizaje adaptativas y una convergencia más rápida y estable, especialmente en el entrenamiento de modelos complejos como las redes neuronales profundas.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84893cbf-6ff7-435f-85c9-c23268074c16",
   "metadata": {},
   "source": [
    "<a id=\"parte-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd2a63-75cf-40e0-9c01-47c28066f513",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightgreen\">**Ejemplos de optimización** </span>\n",
    "***\n",
    "\n",
    "<span style=\"color:gold\">**Función cuadrática** </span>\n",
    "\n",
    "Vamos a implementar el algoritmo de Descenso del Gradiente para la función $\\space y=x^{2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d447564-5b28-4eda-a06c-e47cdc94796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa9afde-09b9-4c08-a4e3-e9c272033000",
   "metadata": {},
   "source": [
    "Usaremos una visualización interactiva para controlar el proceso:\n",
    "\n",
    "> El parámetro `iteration` controla qué iteración del proceso queremos ver. <br>\n",
    "> El parámetro `learning_rate` controla la tase de aprendizaje del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfde39a-963d-4293-98f0-e907fcbfd0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que ilustra el proceso de Gradient Descent\n",
    "def gradient_descent_plot(iteration=0, learning_rate=0.01):\n",
    "    # Posición inicial de la gradiente\n",
    "    current_pos = (90, y_function(90))\n",
    "\n",
    "    # Cálculo del gradiente final (Descenso del Gradiente)\n",
    "    if iteration:\n",
    "        for _ in range(iteration):\n",
    "            new_x = current_pos[0] - (learning_rate * y_derivative(current_pos[0]))\n",
    "            new_y = y_function(new_x)\n",
    "            current_pos = (new_x, new_y)        \n",
    "    \n",
    "    # Figura principal\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    \n",
    "    # Figura de líneas\n",
    "    ax.plot(x, y)\n",
    "    ax.scatter(current_pos[0], current_pos[1], color=\"red\")\n",
    "\n",
    "    # Grilla\n",
    "    ax.grid(lw=0.5, alpha=0.5, c=\"k\", ls=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Texto\n",
    "    ax.set_title(\"Gradient Descent\")\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$x^{2}$\")\n",
    "    \n",
    "    # Mostrar el gradiente y el learning rate\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f\"X: {current_pos[0]:.2f}, Y: {current_pos[1]:.2f}\")\n",
    "    print(f\"Tasa de aprendizaje: {learning_rate}\")\n",
    "    print(f\"Gradiente: {y_derivative(current_pos[0]):.8f}\")\n",
    "    \n",
    "    # Mostrar la figura\n",
    "    plt.show()\n",
    "\n",
    "widgets.interact(gradient_descent_plot, iteration=(0, 1000, 1),\n",
    "                 learning_rate=[10**i for i in range(-5, 1, 1)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc410b56-66c7-4a8e-9aa6-aa56072963c8",
   "metadata": {},
   "source": [
    "Podemos observar que, al utilizar tasas de aprendizaje muy bajas, el algoritmo desciende muy lentamente, incluso después de muchas iteraciones. En contraste, <span style=\"color:#43c6ac\">con tasas de aprendizaje altas, el algoritmo puede converger más rápidamente al óptimo local de la función de coste</span>. \n",
    "\n",
    "Sin embargo, es importante tener en cuenta que <span style=\"color:#43c6ac\">una tasa de aprendizaje excesivamente alta puede impedir que el algoritmo converja al óptimo local</span>, ya que descenderá demasiado rápido y se desplazará a lugares aleatorios en la superficie de la función de coste.\n",
    "\n",
    "***\n",
    "<span style=\"color:gold\">**Función trigonométrica** </span>\n",
    "\n",
    "También vamos a probar el algoritmo de Descenso del Gradiente en la función $\\space y=sen(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602da5f-2610-4ebc-b83f-c062abc71e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función a optimizar (función de coste)\n",
    "def y_function(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "# Derivada de la función (gradiente)\n",
    "def y_derivative(x):\n",
    "    return np.cos(x)\n",
    "\n",
    "# Espacio lineal de x\n",
    "x = np.arange(0, 10, 0.1)\n",
    "\n",
    "# Espacio lineal de y\n",
    "y = y_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46321bb-4496-4c5f-9f1e-e51b5e1fb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_plot(iteration=0, learning_rate=0.01):\n",
    "    # Posición inicial de la gradiente\n",
    "    current_pos = (3, y_function(3))\n",
    "\n",
    "    # Cálculo del gradiente final (Descenso del Gradiente)\n",
    "    for _ in range(iteration):\n",
    "        new_x = current_pos[0] - (learning_rate * y_derivative(current_pos[0]))\n",
    "        new_y = y_function(new_x)\n",
    "        current_pos = (new_x, new_y)\n",
    "    \n",
    "    # Figura principal\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    \n",
    "    # Figura de líneas\n",
    "    ax.plot(x, y)\n",
    "    ax.scatter(current_pos[0], current_pos[1], color=\"red\")\n",
    "\n",
    "    # Grilla\n",
    "    ax.grid(lw=0.5, alpha=0.5, c=\"k\", ls=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Mostrar el gradiente y el learning rate\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f\"X: {current_pos[0]:.2f}, Y: {current_pos[1]:.2f}\")\n",
    "    print(f\"Tasa de aprendizaje: {learning_rate}\")\n",
    "    print(f\"Gradiente: {y_derivative(current_pos[0]):.8f}\")\n",
    "\n",
    "    # Texto\n",
    "    ax.set_title(\"Gradient Descent\")\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$sen(x)$\")\n",
    "    \n",
    "    # Mostrar la figura\n",
    "    plt.show()\n",
    "\n",
    "widgets.interact(gradient_descent_plot, iteration=(0, 1000, 1), learning_rate=[10**i for i in range(-4, 2, 1)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbabdc9-5bc5-4187-bb36-82c79a96eaef",
   "metadata": {},
   "source": [
    "Al aplicar el descenso del gradiente a una función trigonométrica, obtenemos resultados consistentes con los observados en la función cuadrática: las tasas de aprendizaje bajas resultaron en una convergencia lenta, mientras que las tasas altas permitieron una convergencia rápida, aunque con el riesgo de no alcanzar el óptimo debido a saltos aleatorios en la superficie de la función de coste.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f21e1f-a138-4060-9b7d-155aff134af1",
   "metadata": {},
   "source": [
    "<a id=\"parte-3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2542c-c716-494e-bb4d-4ae0990801d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightgreen\">**Optimización de parámetros en modelos lineales** </span>\n",
    "***\n",
    "\n",
    "Exploraremos cómo se puede utilizar el algoritmo de Descenso del Gradiente para optimizar los parámetros $w$ y $b$ de un modelo lineal de la forma $\\space y = wx + b$. \n",
    "\n",
    "Este proceso es fundamental para ajustar el modelo de modo que se minimice la función de coste, permitiendo así que las predicciones sean lo más precisas posible. A través de iteraciones sucesivas, ajustaremos estos parámetros para encontrar los valores óptimos que mejor se adapten a los datos de entrenamiento, demostrando la eficacia del descenso del gradiente en la optimización de modelos lineales.\n",
    "\n",
    "El objetivo es encontrar la relación lineal entre una variable independiente $x$ y una variable dependiente $y$. Un modelo lineal simple se define como:\n",
    "\n",
    "<center>\n",
    "    $ \\Large y(x) = wx + b $\n",
    "</center>\n",
    "\n",
    "> Donde:\n",
    "> - $w$ es el coeficiente que representa la pendiente de la recta\n",
    "> - $b$ es la intersección con el eje Y\n",
    "\n",
    "Para ajustar el modelo a los datos, <span style=\"color:#43c6ac\">necesitamos minimizar la función de pérdida (loss)</span>, que en este caso es el error cuadrático medio (MSE). La función de pérdida se define como:\n",
    "\n",
    "<center>\n",
    "    $ \\Large \\text{loss} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - y(x_i))^2 $\n",
    "</center>\n",
    "\n",
    "> Donde \n",
    "> - $N$ es el número de muestras\n",
    "> - $y_i$  es el valor real de la variable dependiente\n",
    "> - $y(x_i)$ es el valor predicho por el modelo para la muestra $i$\n",
    "\n",
    "Para minimizar esta función de pérdida, utilizamos el algoritmo de Descenso del Gradiente. Calculamos los gradientes de la función de pérdida con respecto a los parámetros $w$ y $b$, y actualizamos estos parámetros iterativamente en la dirección opuesta al gradiente. Las actualizaciones de los parámetros se realizan según las siguientes fórmulas:\n",
    "\n",
    "<center>\n",
    "    $ \\Large w = w - \\alpha \\frac{\\partial \\text{loss}}{\\partial w} $\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    $ \\Large b = b - \\alpha \\frac{\\partial \\text{loss}}{\\partial b} $\n",
    "</center>\n",
    "\n",
    "> Donde:\n",
    "> - $\\alpha\\,$ es la <span style=\"color:gold\">tasa de aprendizaje</span>, un hiperparámetro que controla el tamaño del paso de actualización.\n",
    "\n",
    "Este proceso <span style=\"color:#43c6ac\">se repite hasta que la función de pérdida se minimiza y el modelo se ajusta adecuadamente a los datos </span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62ff70-e0d1-4357-bae8-2083bb15b0e4",
   "metadata": {},
   "source": [
    "Empezaremos definiendo los datos de entrada `x` e `y`, así como los parámetros  `w` y `b`, que inicialmente pueden tomar cualquier valor.\n",
    "\n",
    "> Generaremos datos sintéticos correspondientes a una función $\\space y = 2x + c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddc362-f484-4e94-9e75-63741578aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrada\n",
    "x = np.random.randn(25)\n",
    "y = (2 * x) + np.random.rand() # Función y = 2x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ffbf0-8b9a-4e7b-9f07-bbf65853b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a482c82-7d87-4d3c-9fc7-7968f507c3d6",
   "metadata": {},
   "source": [
    "Implementaremos una función `descend` que utiliza el algoritmo de descenso del gradiente para optimizar los parámetros $w$ y $b$ de un modelo lineal. Esta función recibe como entrada los datos `x` e `y`, los parámetros iniciales `w` y `b`, y la tasa de aprendizaje. \n",
    "\n",
    "Dentro de la función, se calculan las derivadas parciales de la función de pérdida con respecto a $w$ y $b$ a través de un bucle que recorre los datos de entrada. Luego, se actualizan los valores de estos parámetros restando el producto de la tasa de aprendizaje y el promedio de las derivadas parciales. La función devuelve dichos parámetros optimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1bc6b6-07e2-4e29-a1c7-0b09891b2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo de Descenso del Gradiente\n",
    "def descend(x, y, w, b, learning_rate):\n",
    "    dldw = 0.0\n",
    "    dldb = 0.0\n",
    "    N = x.shape[0]\n",
    "\n",
    "    # Actualizar las derivadas de la función de pérdida con respecto a w y b\n",
    "    for xi, yi in zip(x, y):\n",
    "        dldw += -2 * (xi * (yi - ((w * xi) + b)))\n",
    "        dldb += -2 * (yi - ((w * xi) + b))\n",
    "\n",
    "    # Actualizar los valores de w y b\n",
    "    w -= learning_rate * (1 / N) * dldw\n",
    "    b -= learning_rate * (1 / N) * dldb\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca2e66-18b1-405c-ac22-a96d991d7d04",
   "metadata": {},
   "source": [
    "Ahora, vamos a graficar los puntos usando una visualización interactiva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742a038-5469-4775-aaf7-faac2d9f5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_plot(iteration=0, learning_rate=0.01):\n",
    "    # Parámetros iniciales\n",
    "    w, b = 0., 0.\n",
    "    loss = np.sum(y ** 2, axis=0) / x.shape[0]\n",
    "   \n",
    "    # Realizar ajustes de manera iterativa\n",
    "    for epoch in range(iteration):\n",
    "        epoch += 1\n",
    "        w, b = descend(x, y, w, b, learning_rate) # Actualizar w y b\n",
    "        yhat = w * x + b\n",
    "        loss = np.sum((y - yhat) ** 2, axis=0) / x.shape[0]\n",
    "        \n",
    "    # Figura principal\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    # Espacio lineal para la predicción de Y\n",
    "    _x = np.arange(x.min(), x.max(), 0.1)\n",
    "    _y = (w * _x) + b\n",
    "    \n",
    "    # Diagrama de dispersión\n",
    "    ax.plot(_x, _y, c=\"red\")\n",
    "    ax.scatter(x, y, c=\"blue\", s=10)\n",
    "    \n",
    "    # Texto\n",
    "    ax.set_title(f\"Modelo lineal\\nw: {w:.4f},  b: {b:.4f},  loss: {loss:.4f}\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    # Grilla\n",
    "    ax.grid(lw=0.5, alpha=0.5, c=\"k\", ls=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Mostrar la figura\n",
    "    plt.show()\n",
    "\n",
    "widgets.interact(linear_model_plot, iteration=(0, 500, 1), learning_rate=[0.001, 0.01, 0.1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a227d4-88d4-42e5-a331-2305e5a6d718",
   "metadata": {},
   "source": [
    "Este gráfico ilustra de manera eficiente cómo el algoritmo de Descenso del Gradiente ajusta los parámetros `w` y `b` a lo largo de múltiples iteraciones. Inicialmente, los parámetros pueden no estar bien ajustados, pero <span style=\"color:#43c6ac\">a medida que el algoritmo progresa, estos se actualizan continuamente en la dirección que minimiza la función de pérdida</span>. \n",
    "\n",
    "El resultado final es un modelo lineal que se ajusta de manera óptima a los datos de entrada, logrando predicciones precisas y reduciendo el error al mínimo posible. Este proceso visualiza la convergencia hacia los valores óptimos de `w` y `b`, demostrando la efectividad del Descenso del Gradiente en la optimización de modelos lineales.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622689f-c9b4-4370-98ce-ccd87a2d0958",
   "metadata": {},
   "source": [
    "<a id=\"parte-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c579531-1e5c-4eda-8ca4-513e6136d33a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightgreen\">**En conclusión...** </span>\n",
    "***\n",
    "\n",
    "El algoritmo de Descenso del Gradiente es una herramienta fundamental en el campo del aprendizaje automático y la optimización. Su capacidad para ajustar los parámetros del modelo de manera iterativa y eficiente lo convierte en una opción preferida para entrenar modelos lineales y no lineales. A través de la minimización de la función de pérdida, el algoritmo busca el mejor ajuste posible para los datos, mejorando continuamente la precisión de las predicciones a medida que se optimizan los parámetros. Su flexibilidad y simplicidad lo hacen aplicable a una amplia gama de problemas y tipos de datos.\n",
    "\n",
    "<span style=\"color:#43c6ac\">Una de las principales ventajas del descenso del gradiente es su adaptabilidad.</span> Existen múltiples variantes, como el descenso del gradiente estocástico (SGD) o el algoritmo Adam, que mejoran la velocidad de convergencia y la estabilidad del proceso de optimización. Estas variantes permiten a los practicantes ajustar y personalizar el algoritmo para que se adapte mejor a sus necesidades específicas y a las características del problema que están resolviendo. Además, la elección adecuada de la tasa de aprendizaje y la correcta implementación del algoritmo pueden marcar una gran diferencia en la eficiencia y el éxito del entrenamiento del modelo.\n",
    "\n",
    "Sin embargo, el descenso del gradiente también presenta desafíos, como la posibilidad de quedar atrapado en mínimos locales o la necesidad de un ajuste cuidadoso de la tasa de aprendizaje para evitar problemas de convergencia. A pesar de estos desafíos, su implementación y comprensión son esenciales para cualquier profesional en el campo del aprendizaje automático y la inteligencia artificial.\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
